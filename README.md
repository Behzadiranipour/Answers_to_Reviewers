A robust framework for enhancing the performance and interpretability of
both classical machine learning and deep neural network models through systematic synthetic data generation.
This research investigates the impact of synthetic data volume on model bias,
variance, and feature importance stability across diverse model architectures.


ðŸ“Š Key Contributions
Volume Sensitivity Analysis: Systematic evaluation of synthetic data impact across 1,390 to 5,390 samples

Multi-Architecture Validation: Comparative analysis of 8 classical ML models and 7 neural network architectures

Bias-Variance Decomposition: Quantitative assessment of synthetic data effects on model generalization

Interpretability Stability: Bootstrap-validated SHAP analysis with enhanced feature importance consistency


<img width="940" height="665" alt="image" src="https://github.com/user-attachments/assets/a20a50dd-77f6-4d5f-8469-4e98f23f9c21" />




<img width="940" height="669" alt="image" src="https://github.com/user-attachments/assets/11efb7f4-59f8-4993-9a03-9b94130d53b2" />


